### 4장까지 진행 과정 정리

1. 깃헙 등 저장소에 올린 어플리케이션 소스 코드를 내려받아 도커 컨테이너 이미지로 빌드(docker build)
2. 빌드한 컨테이너 이미지를 쿠버네티스에서 사용할 수 있도록 레지스트리에 등록(docker push)
3. 레지스트리에 등록된 이미지를 기반으로 쿠버네티스 오브젝트를 생성(kubectl create)
4. 생성한 오브젝트(pod/deployement)를 외부에서 접속할 수 있도록 서비스 형태로 노출(kubectl expose)

이런 과정을 파이프 라인이라고 한다.

이를 도구를 통해 자동화할 수 있다.

자동화는 크게 지속적 통합(CI, Continuous Integration), 지속적 배포(CD, Continuous Deployment) 두 가지로 정의되고, 일반적으로 둘을 합쳐 CI/CD라고 한다.

### 컨테이너 인프라 환경에서 CI/CD

CI은 일반적으로 코드를 커밋하고 빌드했을 때 정상적으로 작동하는지 반복적으로 컴증해 애플리케이션의 신뢰성을 높이는 작업이다. CI 과정을 마친 애플리케이션은 신뢰할 수 있는 상태가 된다. 

CD는 CI 과정에서 생성된 신뢰성 있는 애플리케이션을 실제 사용 환경에 자동으로 배포하는 것을 의미한다. 배포할 때 고려할 사항이 여러 가지 있는데, 이를 CD에 미리 정의하면 실수를 줄이고, 실제 적용 시간도 최소화할 수 있다.

개발자가 소스를 커밋하고 푸시하면 CI 단계로 들어간다. CI 단계에서는 애플리케이션이 자동 빌드되고 테스트를 거쳐 배포할 수 있는 애플리케이션인지 확인한다. 테스트를 통과하면 신뢰할 수 있는 애플리케이션으로 간주하고 CD 단계로 넘어간다. CD 단계에서는 애플리케이션을 컨테이너 이미지로 만들어서 파드, 디플로이먼트, 스테이트풀셋 등 다양한 오브젝트 조건에 맞춰 미리 설정한 파일을 통해 배포한다.

**CI/CD 도구**

| 구분 | 팀시티 | 깃허브 액션 | 뱀부 | 젠킨스 |
| --- | --- | --- | --- | --- |
| 설치 방식 | 직접 설치 | 깃허브 연동 | 직접 설치 | 직접 설치 |
| 연계 기능 | 보통 | 보통 | 부족 | 매우 많음 |
| 가격 | 무료/유료 | 무료/유료 | 유료 | 무료 |
| 기능 추가 | 보통 | 매우 다양 | 보통 | 매우 다양 |
| 범용성 | 보통 | 매우 큼 | 보통 | 매우 큼 |
| 정보량 | 부족 | 많음 | 많음 | 매우 많음 |

이외에 클라우드 서비스에서 제공하는 AWS CodeBuilde, CodePipeline, CodeDeploy, GCP CloudBuild, Azure Pipeline 등이 있다. 배포가 중요한 환경이라면 CD 기능이 중점인 Spinnaker나 아르고 CD(Argo CD)를 선택적으로 도입할 수도 있다.

개발자가 작성한 애플리케이션 코드를 소스 코드 저장소에 푸시하면 쿠버네티스 내부에 설치된 젠킨스는 앱 코드를 빌드하고 레지스트리에 푸시한 후 쿠버네티스에서 사용 가능한 형태로 배포한다. 젠킨스는 작업 내용을 아이템 단위로 정의하고 조건에 따라 자동으로 작업을 수행해 효율을 높이고 실수를 줄인다.

컨테이너 인프라 환경에서 젠킨스를 사용하는 주된 이유는 애플리케이션을 컨테이너로 만들고 배포하는 과정을 자동화하기 위함이다. 젠킨스는 컨트롤러와 에이전트 형태를 구성한 다음 배포해야 하며 여기에 필요한 설정을 모두 넣어야 한다. 동적인 변경 사항을 간편하고 빠르게 적용할 수 있도록 도와주는 도구가 2가지가 있다. 하나는 커스터마이즈고 다른 하나는 헬름이다. 

### 배포 간편화 도구 비교하기

| 구분 | kubectl | kustomize | Helm |
| --- | --- | --- | --- |
| 설치 방법 | 쿠버네티스 기본 포함 | 별도 실행 파일 또는 쿠버네티스에 통합 | 별도 설치 |
| 배포 대상 | 정적 yaml 파일 | 커스터마이즈 파일 | 패키지(차트) |
| 주 용도 | 오브젝트 관리 및 배포 | 오브젝트의 가변적 배포 | 패키지 단위 오브젝트 배포 및 관리 |
| 가변적 환경 | 대응 힘듦(yaml 수정 필요) | 간단한 대응 가능 | 복잡한 대응 가능 |
| 기능 복잡도 | 단순 | 보통 | 복잡함 |

### 커스터마이즈의 작동 원리

커스터마이즈는 yaml 파일에 값을 정의해서 사용자가 원하는대로 커스터마이징할 수 있다. kustomize 명령과 create 옵션으로 kustomization.yaml이란 기본 매니페스트를 만들고, 이 파일에 변경해야 하는 값들을 적용한다. 그리고 build 옵션으로 변경할 내용이 적용된 최종 yaml 파일을 저장하거나 변경된 내용이 바로 실행되도록 지정한다.

커스터마이즈로 MetalLB를 구성해보자.

- kustomization.yaml 파일에 원하는 내용을 담고
- 그걸 반영한 MetalLB 매니페스트를 생성하고
- 이 매니페스트를 통해 배포

```bash
# 커스터마이즈 압축 파일을 내려 받은 후 이를 해제하고 /usr/local/bin으로 이동
~/~~~/kustomize-install.sh

# 커스터마이즈에서 리소스 및 주소 할당 영역(pool)을 구성할 때 사용하는 파일 확인을 위해
# 디렉터리를 이동하고 metallb-l2config.yaml, metallb.yaml, namespace.yaml 파일 확인
cd ~/~~/5.2.2
ls

# kustomization.yaml 생성
# --namespace : 작업의 네임스페이스 설정
# --resource : 커스터마이즈 명령을 이용해 kustomization.yaml를 만들기 위한 소스 파일 정의
kustomize create --namespace=metallb-system --resources namespace.yaml, metallb.yaml, metallb-l2config.yaml

# 생성된 yaml 파일 확인
cat kustomization.yaml

# 설치된 이미지를 안정적인 버전으로 유지하기 위해 이미지 태그를 v0.8.2로 지정
kustomize edit set image metallb/controller:v0.8.2
kustomize edit set image metallb/speaker:v0.8.2

# tag 설정 확인
cat kustomization.yaml

# Metallb 설치를 위한 매니페스트 생성
kustomize build

# 배포
kustomize build | kubectl apply -f -

# 정상 배포됐는지 확인
kubectl get pods -n metallb-system

# tag 확인
kubectl describe pods -n metallb-system | grep Image:

# 커스터마이즈로 metallb가 생성됐으니 디플로이먼트 1개 배포 후 load balancer 타입으로 노출하고
# ip 정상 할당되는지 확인
kubectl create deployment echo-ip --image=sysnet4admin/echo-ip
kubectl expose deployment echo-ip --type=LoadBalancer --port=80
kubectl get service echo-ip

# 호스트 노트북에서 192.168.1.11로 접속해 정상 응답 확인
```

### 헬름의 작동 원리

헬름:  쿠버네티스에서 패키지를 쉽게 배포할 수 있도록 패키지를 관리하는 쿠버네티스 전용 패키지 매니저

- 일반적으로 패키지는 실행 파일 + 실행 환경에 필요한 의존성 파일 + 환경 정보 묶음
- 외부 저장소에서 패키지 정보를 받아와 패키지를 안정적으로 관리하는 도구
- 자바의 maven, 리눅스의 yum, apt, 파이썬의 pip라고 생각하면 됨!

패키지 매니저의 역할은 기본적으로 쉬운 설치와 관리다. 그 외에는..

- 패키지 검색
- 패키지 관리: 저장소에서 패키지 정보 확인, 패키지 설치, 삭제, 업그레이드, 되돌리기 등
- 패키지 의존성 관리: 설치할 때 의존하는 소프트웨어 같이 설치, 같이 삭제
- 패키지 보안 관리: 체크섬이라는 값으로 해당 패키지의 소트프웨어나 의존성이 변조됐는지 검사 가능

추가로 헬름을 사용하면 주소 할당 영역도 변경이 가능하다.

헬름 기본 저장소는 아티팩트허브(artifacthub.io)로, 다른 패키지 매니저처럼 외부에 있다. 다른 저장소와 달리 패키지에 대한 경로만 제공한다. 

아티팩트허브 검색을 통해 사용자가 찾고자 하는 애플리케이션 패키지를 검색해 저장된 주소를 확인한다. 이 주소는 각 애플리케이션을 개발하는 주체가 관리한다. 사용자는 설치하려는 애플리케이션의 차트 저장소 주소를 아티팩트허브에서 얻으면 헬름을 통해 주소를 등록한다. 그리고 이를 최신으로 업데이트한 후 차트를 내려받고 설치한다. 이렇게 헬름을 통해 쿠버네티스에 설치된 애플리케이션 패키지를 릴리스라고 한다.

헬름을 통해 배포된 릴리스를 다시 차트를 사용해 업그레이드 할 수 있고 원래대로 되돌릴 수 있다. 또한, 사용하지 않는 헬름 릴리스를 제거할 수도 있다. 

### 헬름으로 MetalLB 한 번에 만들기

```bash
# 헬름 설치, 호환성 이슈로 버전을 고정하고 다운함
export DESIRED_VERSION=v3.2.1; ~/~~~/helm-install.sh

# 아티팩트허브에서 metallb를 검색해 주소를 확인

# 실제 저장소를 등록해 metallb 설치 준비
helm repo add edu https://iac-source.github.io/helm-charts

# 정상 등록되었는지 확인
helm repo list

# 헬름으로 차트 저장소를 추가한 시점의 차트를 로컬 캐시를 저장해 install과 같은 작업 수행시 먼저 
# 로컬에 있는 캐시 정보 참조

# 저장소 추가 이후 변경된 차트가 있으면 변경된 정보를 캐시에 업데이트 할 수 있게 최신 차트 정보 업데이트
helm repo update

# 등록, 업데이트한 저장소로부터 metallb 설치
helm install metallb edu/metallb \
--namespace=metallb-system \
--create-namespace \
--set controller.tag=v0.8.3 \
--set speaker.tag=v0.8.3 \
--set configmap.ipRange=192.168.1.11-192.168.1.29

# 설치된 metallb가 정상 상태인지 확인
kubectl get pods -n metallb-system
kubectl get configmap -n metallb-system

# helm set 옵션 잘 적용되었는지 확인
kubectl describe pods -n metallb-system | grep Image:

# 헬름으로 metallb가 생성됐으니 디플로이먼트 1개 배포 후 load balancer 타입으로 노출하고
# ip 정상 할당되는지 확인
kubectl create deployment echo-ip --image=sysnet4admin/echo-ip
kubectl expose deployment echo-ip --type=LoadBalancer --port=80
kubectl get service echo-ip

# 호스트 노트북에서 192.168.1.11로 접속해 정상 응답 확인
```


### 헬름으로 젠킨스 설치하기

```bash
# 젠킨스로 지속적 통합을 하는 과정에 컨테이너 이미지를 레지스트리에 푸시하는 단계가 있음
# 실습을 위해 레지스트리를 우선 구성
docker ps -f name=registry

# 헬름으로 설치되는 젠킨스는 pod에서 동작하는 애플리케이션이므로 PV를 마운트하지 않으면
# pod이 재시작할 때 내부 볼륨에 저장하는 모든 데이터가 삭제됨
# 이를 방지하기 위해 NFS 디렉터리를 만들고 미리 정의된 nfs-exporte.sh jenkins를 실행
# 해당 스크립트에는 NFS용 디렉터리를 만들고 이를 NFS 서비스로 생성하는 과정이 담김
~/~~/nfs-exporter.sh jenkins

# 만들어진 디렉터리에 부여된 사용자 id, 그룹 id 확인
ls -n /nfs-shared

#젠킨스를 헬름 차트로 설치해 앱을 사용하면 젠킨스의 여러 설정 파일과 구성 파일들이 PVC를 통해 PV에 파일로 저장됨
# 이 때 PV에 적절한 접근 ID를 부여하지 않으면 PVC를 사용해 파일을 읽고 쓰는 기능에 문제가 생길 수 있음
# 문제 방지를 위해 젠킨스 PV가 사용할 NFS 디렉터리에 대한 접근 ID를 1000번으로 설정
chown 1000:1000 /nfs_shared/jenkins/
ls -n /nfs_shared

# 사전 구성된 jenkins-volume.yaml 파일을 이용해 PV, PVC 구성하고 확인
kubectl apply -f ~/~~/jenkins-volume.yaml
kubectl get pv jenkins
kubectl get pvc jenkins

# 젠킨스 설치를 위해 필요한 인자를 포함해 사전 구성된 jenkins-install.sh를 실행해 설치
~/~~/jenkins-install.sh

# 젠킨스 디플로이먼트 정보를 비교해서 보기 위해 디플로이먼트 배포 확인
# 젠킨스가 마스터 노드에 있는 걸 확인
kubectl get deployment
kubectl get service jenkins
kubectl get pod -o wide

# 마스터에도 pod이 배포 될 수 있을까?
# 상태 비교 (nl : number lines of files, 줄 번호 추가)
kubectl get node m-k8s -o yaml | nl
...
taints:
	- effect: NoSchedule
	  key: node-role.kubernetes.io/master

...
tolerations:
- effect: NoSchedule
	key: node-role.kubernetes.io/master

# 출력되는 사항 중 taints, tolerations이 이런 결과를 만듦
```

일반적으로 테인트와 톨러레이션은 혼합해서 사용함

테인트: 손에 잡기 싫은 것, 가지지 말았으면 하는 것

톨러레이션: 테인트를 피하기 위해 참아내야 하는 것

사전적인 의미로는 이 정도로 이해하면 된다.

쿠버네티스에선 사전적인 의미와는 반대다. 매우 특별하게 취급해야 하는 것을 테인트로 설정하고, 쉽게 접근하지 못하게 만든다. 그리고 톨러레이션이란 특별한 키를 가져야만 여기에 출입할 수 있게 한다.

즉, 현재 상태에서 마스터 노드에 테인트가 설정돼 있어 특별한 목적으로 사용되는 노드라고 명시해 두었다. 일반적으로 마스터 노드 이외에도 GPU 노드, DB 전용 노드 등의 특별한 목적으로 사용될 때 주로 사용한다.

현재 이 예시에선 관리 편의를 위해 젠킨스 컨트롤러가 여러 곳에 스케줄되지 않고 마스터 노드에서만 스케줄될 수 있게 구성했다. 

테인트와 톨러레이션의 관계를 정의하는 것으로 배포를 유연하게 만들 수 있다.

테인트는 key, value, 그리고 key의 값에 따른 효과의 조합을 통해 테인트를 설정한 노드의 pod 배치 기준을 제시한다. 톨러레이션은 key, value, 효과(effect), 연산자(operator)를 갖고 있다.

테인트의 키와 값의 조합은 테인트를 설정한 노드가 어떤 노드인지 구분하기 위해 사용한다. 키는 필수로 설정해야 하지만 값은 생략할 수 있다. 위에 나온 key: [node-role.kubernetes.io/master](http://node-role.kubernetes.io/master) 는 이 노드가 마스터의 역할을 함을 나타내기 위함이다.

효과(effect)는 테인트와 톨러레이션의 요소인 키 또는 값이 일치하지 않는 pod가 노드에 스케줄되려고 하는 경우 어떤 동작을 할 것인지 나타낸다. 효과는 NoSchedule, PreferNoSchedule, NoExecute을 값으로 가질 수 있는데 효과에 따라 테인트를 설정한 노드는 pod을 새로 배치하는 경우와 pod가 이미 배치된 노드에 대한 동작이 다르다. 

| 효과 | 테인트가 설정된 노드에 대한 신규 배치 | pod이 배치된 노드에 테인트 설정 |
| --- | --- | --- |
| NoSchedule | 노드에 pod 배치 거부 | 노드에 존재하는 pod 유지 |
| PreferNoSchedule | 다른 노드에 pod 배치가 불가능할 때는 노드에 pod 배치 | 노드에 존재하는 pod 유지 |
| NoExecute | 노드에 pod 배치를 거부 | pod을 노드에서 제거 |

톨러레이션에서 키와 효과는 반드시 일치해야 한다. 연산자는 기본적으로 Equal로 동작해 테인트와 톨러레이션을 비교하는 역할을 한다. Exist 연산자는 비교할 키와 값이 존재한다는 가정으로 테인트에 진입할 수 있는 만능 키로 바꿔주는 역할을 한다.

헬름을 통해 젠킨스를 설치했던 스크립트인 [jenkins-install.sh](http://jenkins-install.sh) 내용을 살펴보자.

```bash
#!/usr/bin/env bash

# 기본 설정으로 30분 넘게 사용하지 않으면 세션이 종료되므로 실습에 방해되니
# 세션 유효시간을 1440분(하루)로 변경, 세션 정리 시간 또한 86400초(하루)로 설정
jkopt1="--sessionTimeout=1440"
jkopt2="--sessionEviction=86400"

# 기본 설정으론 시간대가 맞지 않으니 따로 설정
jvopt1="-Duser.timezone=Asia/Seoul"

# 쿠버네티스를 위한 젠킨스 에이전트 노드 설정은 Pod Template을 통해 설정값이 입력됨
# 문제는 가상 머신인 마스터 노드가 재시작하게 되면 이 설정이 초기화되니 
# 설정값을 미리 입력해둔 yaml을 깃헙 저장소에서 가져오게 설정 
jvopt2="-Dcasc.jenkins.config=https://raw.githubusercontent.com/sysnet4admin/_Book_k8sInfra/main/ch5/5.3.1/jenkins-config.yaml"

# edu 차트 저장소의 jenkins 차트를 이용해 jenkins 릴리스를 설치
helm install jenkins edu/jenkins \

# PVC 동적 프로비저닝을 사용할 수 없는 가상 머신 환경이므로 이미 만들어둔 jenkins라는 이름의
# PVC 사용을 설정
--set persistence.existingClaim=jenkins \

# 젠킨스 접속 시 사용할 관리자 비밀번호를 admin으로 설정
# 이 값을 설정하지 않을 경우엔 설치 과정에서 젠킨스가 임의로 생성한 비밀번호를 사용
--set master.adminPassword=admin \

# 젠킨스의 컨트롤러 pod를 쿠버네티스 마스터 노드 m-k8s에 배치하도록 선택
# nodeSelector: 그 뒤에 따라오는 문자열과 일치하는 레이블을 가진 노드에 pod을 스케줄링
--set master.nodeSelector."kubernetes\.io/hostname"=m-k8s \

# 마스터 노드로 pod 배치를 위한 추가 옵션(이 옵션이 없으면 배치가 안됨)
# 테인트가 설정된 상태이기 때문에 톨러레이션 옵션을 설정(톨러레이션 -> 테인트에 대한 예외)
# 톨러레이션에 관해 key, effect, operataor를 설정
--set master.tolerations[0].key=node-role.kubernetes.io/master \
--set master.tolerations[0].effect=NoSchedule \
--set master.tolerations[0].operator=Exists \

# 젠킨스를 구동하는 pod이 실행될 때 가질 유저 ID, 그룹 ID를 설정
--set master.runAsUser=1000 \
--set master.runAsGroup=1000 \

# 이후 젠킨스 버전에 따른 UI 변경을 막기 위해 젠킨스 버전을 2.249로 픽스
--set master.tag=2.249.3-lts-centos7 \

# 차트로 생성되는 서비스 타입을 로드밸런서로 설정해 외부 IP를 받아옴
--set master.serviceType=LoadBalancer \

# 젠킨스가 http상에서 구동되도록 80포트 지정
--set master.servicePort=80 \

# 젠킨스에 추가로 필요할 설정들을 2~3번째 줄에 변수로 선언함. 이 변수를 호출해 젠킨스에 적용
--set master.jenkinsOpts="$jkopt1 $jkopt2" \

# 젠킨스를 구동하기 위한 환경 설정에 필요한 것들을 위에 변수로 선언해뒀음(4~5번째 줄)
# 이 변수들을 호출해 젠킨스 실행환경(jvm)에 적용함
--set master.javaOpts="$jvopt1 $jvopt2"
```


## 젠킨스 살펴보기

젠킨스 컨트롤러는 마스터 노드에 설치했지만 젠킨스 에이전트는 필요 시 생성디고 작업을 마치면 삭제되는 임시적인 구조를 가짐. 젠킨스 에이전트가 작업 내용들을 삭제 전에 젠킨스 컨트롤러에 저장돼야 하며, 이를 위해 젠킨스 에이전트 서비스가 항상 동작하고 있다.

젠킨스 컨트롤러가 단독 설치될 경우 컨트롤러가 설치된 서버에서 젠킨스 자체 시스템 관리, CI/CD 설정, 빌드 등의 작업을 모두 젠킨스 컨트롤러 단일 노드에서 수행한다. 하지만 컨트롤러-에이전트 구조로 설치할 경우 컨트롤러는 젠킨스 자체의 관리 및 CI/CD와 관련된 설정만을 담당하고 실제 빌드 작업은 에이전트로 설정된 노드에서 이뤄진다.

따라서 컨트롤러 단독 설치는 일반적으로 간단한 테스트에서만 사용되고 주로 컨트롤러-에이전트 구조로 사용한다.

### 젠킨스 접속하기

로그인 후 메인화면 좌측 메뉴

1. 새로운 Item: 젠킨스를 통해 빌드한 작업을 아이템이라고 한다.
2. 사람: 사용자를 관리하는 메뉴. 별도 데이터베이스를 갖고 자체적으로 사용자를 관리하는 방법이 있는데 현재는 데이터베이스가 없는 환경이라 직접 사용자를 관리하도록 구성돼 있다.
3. 빌드 기록: 젠킨스 작업에 대한 성공, 실패, 진행 내역을 여기서 볼 수 있다.
4. Jenkins 관리: 젠킨스의 시스템, 보안, 도구, 플러그인 등 각종 설정을 수행하는 곳
    1. 시스템 설정: 메인 화면에 표시될 문구, 동시에 실행할 수 있는 실행기 개수, 젠킨스르 접속할 수 있는 경로, 관리자 정보, 시스템 전체에 적용할 수 있는 환경변수, 시스템에서 공통적으로 활용해야 하는 플러그인 파일 경로와 설정 정보 등을 이곳에서 설정할 수 있다.
    2. Global Tool Configuration: 빌드 과정에서 사용하는 도구(maven, gradle, jdk, git, docker 등)의 경로 및 옵션 설정. 
    3. 플러그인 관리: 사용할 플러그인 설치, 삭제, 업데이트
    4. 노드 관리: 사용하는 노드 추가, 삭제, 세부 설정, 상태 모니터링. 젠킨스에서도 작업을 수행할 수 있는 각 단위를 노드라고 하고, 노드에 레이블을 붙여 관리하거나 동작 방식을 설정할 수 있다.
    5. Configuration as Code: 젠킨스 설정을 내보내거나 불러올 수 있다. 다른 곳에서 구성한 젠킨스 설정을 옮겨오거나 내 젠킨스 설정을 내보내 공유할 수 있다. 새로운 젠킨스를 구성해 현재 젠킨스 설정을 이전할 때 유용한 메뉴.
    6. Manage Credentials: 젠킨스에서 사용하는 플러그인에 필요한 접근 키, 비밀 키, API 토큰과 같은 접속에 필요한 인증 정보를 관리. 
5. My Views: 젠킨스에서 각종 작업을 분류해 모아서 볼 수 있는 대시보드
6. Lockable Resources: 젠킨스에선 한 번에 여러 작업이 동시에 일어날 수 있다. 이 때 작업이 진행중이라면 옵션에 따라 다른 작업은 대기를 해야 할 수 있다. 이를 동시성 문제라고 하며 젠킨스에서 작업이 끝날 때까지 같은 작업을 하지 못하게 하는 잠금 장치를 Lockable Resoruce로 설정할 수 있다.
7. New View: 대시보드인 View를 생성하는 작업

### 젠킨스 컨트롤러 설정하기

홈화면 젠킨스 관리 > 시스템 설정 에서 젠킨스 컨트롤러를 설정하게 된다.

1. 시스템 메시지: 젠킨스 메인 웹 페이지에서 접속했을 때 나타나는 메시지를 입력한다. 이 메시지를 통해 사용자에게 젠킨스에 대한 소개나 간단한 안내를 할 수 있다.
2. ‘# of executors’: 동시에 빌드를 수행할 수 있는 실행기의 개수를 설정하는 옵션. 이 옵션은 컨트롤러 노드에서 몇 개까지 빌드를 실행할 수 있을 지 설정할 수 있다. 현재 설치된 젠킨스의 경우 에이전트 pod를 통해 빌드 작업을 생성하므로 이 옵션을 0으로 설정하는 것이 바람직하다.
3. Labels: 노드를 구분할 레이블을 지정. 이렇게 설정한 레이블을 통해 Usage 옵션을 사용하면 특정 작업을 어떤 노드에서 작업할지 결정할 수 있다.
4. Usage: 젠킨스의 빌드 작업에 대해 젠킨스 노드가 어떻게 처리할지 설정한다. Use this node as much as possible(이 노드를 가능한 많이 사용) 옵션은 빌드 작업을 수행할 때 별도의 조건 없이 노드에 빌드를 할 수 있는 환경이라면 현재 노드에서 빌드를 진행하도록 설정하는 것이다. 이런 옵션은 일반적인 환경에서 빌드 작업에 적합하다. Only build jobs with label expression matching this node(이 노드와 일치하는 레이블 표현식을 가진 작업만 빌드) 옵션은 빌드와 대상의 레이블이 같아야 빌드할 수 있다. 주로 빌드 환경이 다른 플랫폼에서 빌드를 수행할 때 사용된다.
5. Quiet period: 빌드 작업이 시작될 때까지 잠시 대기하는 시간을 설정하는 값. 단위는 초 단위고, 짧은 시간에 변경된 코드에 대해 중복으로 작업을 수행하지 않고 가장 마지막으로 변경된 코드를 빌드하기 위해 설정한다.
6. SCM checkout retry count: 소스 코드 저장소로부터 파일을 가져오지 못한 경우 몇 번 재시도를 할 지 설정하는 옵션이다. SCM이란 소스 코드 관리의 약자로 소스 코드 통합, 관리, 이력 추적을 위해 사용되는 시스템을 의미한다.
7. Restrict project naming: 젠킨스를 통해 만들어지는 작업의 이름 규칙을 설정하는 옵션이다. 체크박스에 체크하면 이름 규칙을 편집할 수 있는 영역이 생기며 제약 조건은 정규식 패턴으로 작성해 적용할 수 있다. 현재 설치된 젠킨스 전략은 Default로 자유롭게 설정 가능.
8. Jenkins URL: 설치된 젠킨스 컨트롤러의 접속 주소다. 앞서 헬름을 설치할 때 로드밸런서를 통해 설정될 IP인 192.168.1.11을 설정했다. 이 주소는 젠킨스가 외부로 알림을 보내거나 자신의 주소를 알려준다.
9. Resource Root URL: 빌드 결과물과 같은 내용을 외부에 공개하기 위해 사용되는 주소로 Jenkins URL과는 다르다. 이 실습에선 빌드 결과물을 외부로 공개할 수 없는 가상 환경에 구성함으로 설정하지 않음.



### 젠킨스 플러그인 관리하기

젠킨스는 실행되는 모든 기능을 플러그인으로 구현하도록 설계돼 있다.

젠킨스 관리 > 플러그인 관리 메뉴로 이동

메뉴 목록

1. 업데이트된 플러그인 목록
2. 설치 가능: 설치되지 않은 플러그인을 검색해 현재 젠킨스에서 해당 기능을 추가할 수 있음
3. 설치된 플러그인 목록
4. 고급 : 외부와 연결되는 프록시 서버 설정을 할 수 있다. 외부와 연결된 프록시 서버를 통해 내부망에서도 젠킨스를 설치하고 업데이트할 수 있다. 그 외에도 별도의 플러그인 파일을 업로드해 플러그인을 설치할 수 있다.

젠킨스 플러그인을 업그레이드하는 경우 재시작해야 한다.

### 젠킨스 에이전트 설정하기

젠킨스 관리 > 노드 관리 메뉴로 이동

메뉴 목록

1. 신규 노드: 에이전트 노드를 추가. 고정된 여러 대의 서버에서 에이전트 노드를 추가해야 할 때 필요하다.
2. Configure Clouds: 클라우드 환경 기반의 에이전트를 설정할 때 필요하다. 쿠버네티스 위에 설치된 젠킨스의 에이전트에 관한 설정도 이 메뉴에서 함.
3. Node Monitoring: 에이전트 노드 안정성을 위한 각종 모니터링과 관련 사항을 설정
4. 노드 목록: 현재 구성된 노드 목록을 보여준다. 쿠버네티스 상에 설치한 젠킨스는 작업이 진행될 때만 pod 형태릐 에이전트가 생성되고 작업이 끝나면 pod이 사라지기 때문에 작업중이 아니라면 이 목록에는 젠킨스 컨트롤러 노드만 표시된다.

### 쿠버네티스에서 젠킨스 에이전트 구성

Configure Clouds 메뉴로 이동

현재 JCasC(Jenkins Configuration as Code)라는 기능을 사용해 헬름을 통해 젠킨스 설치 시 현재 쿠버네티스 환경에 맞게 많은 설정을 자동화된 상태임.

메뉴 목록

1. Kubernetes: 쿠버네티스 설정 관련 영역
2. Kubernetes Cloud details: 쿠버네티스 클러스터에 접속하기 위한 정보를 설정할 수 있다. 헬름을 통해 쿠버네티스 위에 설치한 젠킨스는 쿠버네티스 클러스터 내부에서 동작하기 때문에 기본값으로 둬도 무방하지만, 쿠버네티스 클러스터 외부에 젠킨스를 설치한 경우에는 이 곳에서 쿠버네티스에 대한 정보를 수정해야 한다.
3. Pod Template: 쿠버네티스 위에 설치된 젠킨스는 작업 시 에이전트를 pod의 형태로 생성한다. 이 곳에서 에이전트로 사용할 pod과 관련된 설정을 한다. 이 때 Pod Template은 젠킨스 컨트롤러를 다시 시작하면 모든 설정이 초기화된다. 이걸 해결하기 위해 헬름 설치 시 미리 구성한 설정값(jenkins-config.yaml)을 읽어 들이도록 구성한 상태.

### 젠킨스 에이전트 템플릿의 상세 내용

hostpath: 쿠버네티스 pod에서 워커 노드에 있는 특정 경로를 마운트해서 pod 내에서 쓸 수 있는 것.

젠킨스의 CI/CD 작업은 실제 에이전트로 동작하는데, 쿠버네티스 환경에서 에이전트가 pod으로 운영되나 이 pod에서는 도커 빌드를 위한 docker 명령, 쿠버네티스 배포를 위한 kubectl 명령이 존재하지 않는다. 가장 쉬운 해결 방법은 호스트 시스템에 있는 도커와 kubectl를 그대로 이용하는 것이다. 따라서 hostpath를 잡아 각 노드에 설치돼 있는 도커와 kubectl를 그대로 이용한다.

**Pod Template 설정**

- Name : 이름 설정
- Labels: 에이전트 노드를 구분할 때 사용할 레이블 설정
- Usage: 노드의 사용방법 설정

**Pod에서 사용할 컨테이너 설정**

- Name: 컨테이너 구분을 위한 이름
- Docker image: 컨테이너에서 사용할 이미지
- Command to run: 여기 적힌 명령은 컨테이너에서 실행할 명령이 된다.
- Environment Variable: 컨테이너 환경변수 설정.

**Volumnes 설정 메뉴 - Add Volume**

- Config Map Volume: 쿠버네티스에 존재하는 ConfigMap 오브젝트를 pod 내부에 연결해 해당 pod에서 사용할 수 있다.
- Empty Dir Volume: 파일 및 내용이 없는 디렉터리를 pod 내부에 생성한다. 주로 컨테이너 간에 공유할 수 있는 디렉터리를 사용할 볼륨으로 생성해 쓴다.
- Host Path Volume: 호스트, 즉 쿠버네티스 워커 노드에 파일 및 디렉터리를 pod에서 사용할 수 있도록 연결해 준다. 이를 통해 pod은 호스트에 위치한 명령이나 데이터를 사용할 수 있고, 필요한 경우 파일을 저장해 pod이 사라진 경우에도 데이터를 보존할 수 있다.
- NFS Volume: NFS 서버에 위치한 원격의 디렉터리를 pod가 사용할 수 있도록 한다.
- Persistent Volume Claim: 쿠버네티스 클러스터에서 PVC로 설정한 볼륨을 pod에서 사용할 수 있도록 한다.
- Secret Volume: 쿠버네티스에 있는 Secret 오브젝트를 pod 내부에 연결해 pod에서 사용할 수 있도록 한다.

젠킨스를 이용한 배포 작업은 내부에서 셸 스크립트 단위로 작업을 나눠 구성할 수 있다.

우리 목적은 젠킨스를 이용해 컨테이너 이미지를 빌드하고 컨테이너를 쿠버네티스에 배포하는 것이다.

이를 위해 젠킨스 내부에서 kubectl, docker 같은 명령어를 사용해야 한다. 하지만 배포되는 pod은 이 명령어들이 포함되어 있지 않으므로 호스트에 존재하는 명령을 pod에서 그대로 사용할 수 있는 Host Path Volume을 사용해 구성한다. 구조적으로는 Host paht(쿠버네티스 워커 노드)에 있는 내용이 Mount path(젠킨스 에이전트 노드)로 설정되는 구조이며, Host Paht Volume으로 추가된 3개의 Host Path Volume은 다음과 같다.

1. (kubectl)Host Path Volume: kubectl 명령을 에이전트 pod 내부에서 쓸 수 있도록 /usr/bin/kubectl 경로를 호스트로부터 연결해 준다. 이를 통해 빌드 작업 중인 쿠버네티스와 관련된 작업을 할 수 있다.
2. (docker)Host Path Volume: docker 명령을 에이전트 pod 내부에서 사용할 수 있도록 /bin/docker 경로를 호스트로부터 연결해 준다. 이를 통해 빌드 작업 중 도커 이미지를 생성하고 저장소로 밀어 넣을 수 있다.
3. (docker.sock)Host Path Volume: kubectl과 API 서버가 통신하는 것처럼 도커도 도커 데몬과 통신하기 위해 API 서버 역할을 하는 docker.sock이 있다. 따라서 이미 호스트에 설치된 /var/run/docker.sock 소켓을 에이전트 파드에 사용하도록 설정해 줬다.

젠킨스 에이전트 pod에서 사용할 서비스 어카운트(service account)와 사용자 ID 및 그룹ID를 설정한다.

메뉴

- 서비스 어카운트: 쿠버네티스 클러스터 및 오브젝트 정보를 조회하기 위한 계정. admin 같은 느낌.
- 사용자 ID: 에이전트 pod이 실행될 때 pod에 부여되는 숫자로 리눅스 사용자에 부여되는 숫자 식별자다. 에이전트 pod이 루트 권한을 가진 사용자 ID를 사용하지 않게 하기 위해서 사용자 ID 값은 1000으로 설정.
- 그룹 ID: 관용적으로 리눅스에서 사용되는 0부터 500까지의 ID는 리눅스 시스템이 사용하는 ID다. 여기서는 에이전트 pod가 시스템에 사용하는 ID를 쓰지 않고 독립적으로 컨테이너를 구동할 수 있게 993으로 설정.

### jenkins 서비스 어카운트를 위한 권한 설정

```bash
// 서비스 어카운트 계정 있는지 확인
kubectl get serviceaccounts

// 서비스 어카운트 계정인 jenkins에 쿠버네티스 클러스에 대한 admin 권한 부여
kubectl create clusterrolebinding jenkins-cluster-admni \
--clusterrole=cluster-admin --serviceaccount=default:jenkins

// 적용 내용 확인을 위해 yaml 파일 출력
kubectl get clusterrolebindings jenkins-cluster-admin -o yaml
```

cluster-admin 역할: 젠킨스 에이전트 pod 생성하거나 pod 내부에서 쿠버네티스 오브젝에 제약 없이 접근 가능. 보통 필요한 영역별로 나눠 권한을 부여하나 여기선 편의상 1개로 퉁침.

서비스 어카운트에 cluster-admin 역할을 부여하고 이를 권한이 필요한 서비스 어카운트에 jenkins를 binding한다. 이런 방식을 **역할 기반 접근 제어**(RBAC, Role-Based Access Control)이라고 한다.

쿠버네티스 역할 부여 구조는 할 수 있는 일과 할 수 있는 주체의 결합으로 이뤄져 있다.

- Rules : 할 수 있는 일의 행동 규칙
    - apiGroups(접근할 수 있는 API의 집합), resources(API 그룹에 분류된 자원 중 접근 가능한 것), verbs(접근 가능한 자원에 대해 할 수 있는 행동 - get, delete, watch 등) 속성을 가진다.
- Role, ClusterRole: 할 수 있는 일을 대표하는 오브젝트
    - role: 특정 namespace에만 접근 가능
    - clusterrole: 쿠버네티스 클러스터 전체에 대해 접근 가능
- RoleBinding, ClusterRoleBinding: 할 수 있는 주체에 대한 정의
    - role, clusterRole은 둘 다 roleRef(할 수 있는 역할의 참조)와 subjects(수행 주체)라는 속성을 갖음
    - role binding: namespace 범위의 접근 제어
    - Cluster role binding: 클러스터 전체 범위의 접근 제어
- Subjects: 접근 제어에서 행위를 수행하는 주체
    - 특정 사용자 또는 그룹, 서비스 어카운트를 속성으로 가질 수 있다.




## 젠킨스로 CI/CD 구현하기

아이템(Item): 새롭게 정의할 작업

CI/CD를 하려면 각각의 작업은 모두 정의가 필요하다. 모든 작업의 정의와 순서를 모아 둔 전체 작업을 프로젝트라고 하는데, 프로젝트를 생성하는 방식은 FreeStyle, Pipeline 등이 있다. 이렇게 프로젝트를 정의하고 생성하는 것을 아이템이라고 하며, 프로젝트 외에 실제로 작업에 도움이 되는 내용들을 정의하는 것도 아이템을 생성한다고 볼 수 있다.

아이템 작업

1. Freestyle project
    1. 자유도가 높은 방식으로, 브라우저에서 사용자가 직접 설정값과 수행할 동작을 입력할 수 있다. 화면에 보이는 항목을 입력하면서 구성할 수 있어 젠킨스 관련 경험이 부족한 사용자도 구성하기 쉽다.
    2. 단, 과정이 복잡한 작업은 구성하기 어렵고, 입력한 항목의 명세서를 별도로 저장하는 과정이 없어 작성한 내용을 공유하기 어렵다.
2. Pipeline
    1. 젠킨스에서 지원하는 고유의 Pipeline 문법으로 코드를 작성해 작업을 정의하는 프로젝트다. Freestyle과 비교해 문법을 사전에 숙지해야 한다는 점 때문에 비교적 진입 장벽이 있다. 그렇지만 더 복잡한 방식의 작업을 정의하는 것이 가능하고 재사용이 가능하다.
    2. 깃헙 같은 곳에 코드를 올릴 때 Pipeline 코드로 작성한 파일을 함께 올려 두면 애플리케이션 코드의 배포 방법을 함께 관리할 수 있어 관리 편의성도 높다.
3. Multi-configuration project
    1. 하나의 소스 코드를 여러 조건의 조합으로 나온 경우의 수에 해당하는 환경에 동시 배포하는 프로젝트다.
4. Folder
    1. 젠킨스의 작업이 늘어나면 늘어날수록 단순하게 관리하기 어려운데 이런 경우 관련 있는 작업들을 분류해둘 필요가 있다. 이럴 경우 분류 가능한 디렉터리를 생성하는 것이 Folder다.
5. Multibranch Pipeline
    1. 하나의 소스 코드 저장소 내에 존재하는 각 브랜치에서 젠킨스 파이프라인 코드가 작성된 파일을 불러와 한 번에 여러 브랜치에 대해 품질 검증, 테스트, 빌드 등의 작업을 할 수 있다.
    

5가지 아이템 중 주로 Freestyle, Pipeline이 사용된다. 

### Freestyle로 간단히 echo-ip 배포하기

여기서 배포할 대상은 IP 주소를 반환하는 간단한 Nginx 웹 서버인 echo-ip다. 

실습을 위해 깃헙에서 갖고 오고, CD를 위해 kubectl create와 expose를 Freestyle 프로젝트에서 배포로 사용하도록 정의한다. 

일단 echo-ip 파일을 확인하자.


- Dockerfile :  echo-ip 도커 이미지를 빌드하는데 사용하는 파일, nginx:stable 사용, 인증과 관련된 파일과 설정파일을 복사 후 실행되도록 구성

```docker
FROM nginx:stable

LABEL Name=echo-ip Version=0.0.5
COPY nginx.conf /etc/nginx/nginx.conf
COPY cert.crt /etc/nginx/conf.d/cert.crt
COPY cert.key /etc/nginx/conf.d/cert.key

CMD ["nginx", "-g", "daemon off;"]
```

- jenkinsfile : pipline 을 위해 작성된 파일

```
pipeline {
  agent any
  stages {
    stage('git scm update') {
      steps {
        git url: 'https://github.com/IaC-Source/echo-ip.git', branch: 'main'
      }
    }
    stage('docker build and push') {
      steps {
        sh '''
        docker build -t 192.168.1.10:8443/echo-ip .
        docker push 192.168.1.10:8443/echo-ip
        '''
      }
    }
    stage('deploy kubernetes') {
      steps {
        sh '''
        kubectl create deployment pl-bulk-prod --image=192.168.1.10:8443/echo-ip
        kubectl expose deployment pl-bulk-prod --type=LoadBalancer --port=8080 \
                                               --target-port=80 --name=pl-bulk-prod-svc
        '''
      }
    }
  }
}
```

- cert.crt : echo-ip의 nginx에서 https접속시 사용하는 인증서 파일

```

-----BEGIN CERTIFICATE-----
MIIDUTCCAjmgAwIBAgIEXGTIcjANBgkqhkiG9w0BAQsFADBZMQswCQYDVQQGEwJL
UjEMMAoGA1UECBMDZ251MQwwCgYDVQQHEwNnbnUxDDAKBgNVBAoTA2dudTEMMAoG
A1UECxMDZ251MRIwEAYDVQQDEwlsb2NhbGhvc3QwHhcNMjAwMTEzMjIzMzIzWhcN
MjEwMTEyMjIzMzIzWjBZMQswCQYDVQQGEwJLUjEMMAoGA1UECBMDZ251MQwwCgYD
VQQHEwNnbnUxDDAKBgNVBAoTA2dudTEMMAoGA1UECxMDZ251MRIwEAYDVQQDEwls
b2NhbGhvc3QwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC30HNtamZw
vphRWKcvQkPsZk/5K9tIawenr5/cyIA8nhyb03ZsRpRDD8n7tSFOMsnvVnvW35GG
zkh8QTaf3SvGbcKPEiX1+xV2tyIMHbmEJ7fhw5qBsE6H8qfLBiirxAEeaweoyikY
zPdbB3pcquXeMhUD31QEWlna+sDmXeM2P7kqZ3VGSCv7by3cip5NLv3smO0HpExw
vd3J/K6VmZsBpQaBnXbUxCoRfdonL4WOA239CyCLOL32eM1UkwLwLTJVEVNrtvJ7
I99IV1dQxLrSjrrgQbZvGe4Vfyzg5ZtjdQVK8T0AZbCHJjWle3IcSgMg6nQizDta
JySET6Iy0VrHAgMBAAGjITAfMB0GA1UdDgQWBBTIb2hOBfAlNRnvgf9yZ6OuZiiH
xTANBgkqhkiG9w0BAQsFAAOCAQEAtTuBNy8UQkYUs7Ud1ymQvHd6kS3hlB8MJA7c
yCw63BLpLl68B/n0gk0Ww8+9Xi7T5AoMIQ9nh6dVK5t+fFn5Qa7UJPsHOR1l1y4V
5ODZOxKx1Q4Tl7zR3uJdroCVQLDeJ6pBKbzPGla3g0ScKvGSDyXucxztMZbGDimp
YXX6uXrty0jYEBab6fFK69pzM2G9E8c2Scno8iS3cKMk/j76mw5R8d8lCOLaQsO7
7yUdcsyir4ujTEgGj5+XNSLmrnRooENb67qINArE3TA8W4MGVD9+eADUkhu6bG8m
AfpkysjU1mqPaspBhDFv52Gcz7kav9rmZexnvc0hDWaACkf1mA==
-----END CERTIFICATE-----
```

- cert.key : echo-ip의 nginx에서 https접속 시 사용하는 비밀 키 파일

```

-----BEGIN RSA PRIVATE KEY-----
MIIEpAIBAAKCAQEAt9BzbWpmcL6YUVinL0JD7GZP+SvbSGsHp6+f3MiAPJ4cm9N2
bEaUQw/J+7UhTjLJ71Z71t+Rhs5IfEE2n90rxm3CjxIl9fsVdrciDB25hCe34cOa
gbBOh/KnywYoq8QBHmsHqMopGMz3Wwd6XKrl3jIVA99UBFpZ2vrA5l3jNj+5Kmd1
Rkgr+28t3IqeTS797JjtB6RMcL3dyfyulZmbAaUGgZ121MQqEX3aJy+FjgNt/Qsg
izi99njNVJMC8C0yVRFTa7byeyPfSFdXUMS60o664EG2bxnuFX8s4OWbY3UFSvE9
AGWwhyY1pXtyHEoDIOp0Isw7WickhE+iMtFaxwIDAQABAoIBAHlx/BF6jxxGkRSN
4kfTHFWAc65JT6RVMsWTv6d7wV5LiNNbr45yQ1rbf7QSRGMKI2lCVqftJpVOjY2q
+JA+7ME5m6Yzc2lF7zR0YsZmjT/HjjJXrimpdvlTVZFKDG0QHz0dsf3PM7/zDCrU
kf/P2fgoVsIsN7J4j42ixvhtZ8VazgZDguwQiKBc+nnsc4QbeR05W8qg61Mf87H4
VwssVaPW9nNZfw+HZvaY6oF4aUvQ3vkOnumxoB9TtxD3P1Qp5Te5WR60r53S63ad
kY5gE4tcgYn2g7l/a9AJQgAZPl6/ovinzZsB5vc+ZsIdaISRFtSlGane7aR/sKc3
qpjWoWECgYEA4Jhm3D/OaExSlV61b0FNqkOJ6ppYoMsafLkNV97l6iw/z6ZlFqrd
+pwrvl7f4tPLGEVrO4UBChFzJmakzB9yaUDpIRd3kfDkz+Bx9ndzBwV7sLItkwJU
O4Lfai0xVCeEgRXiQ2vbtyderDmwWLZXv6heuX31NWMKYXCouqcm3A0CgYEA0YRA
0kIfHSSK/vIAtocrDpnurOODNdnuKgYOYkHbJ/PN6xhUVo5eeRDQOM8s+Tvl7OTI
4OJEmrPthBcpHzeYalTYbHU6KR2clY6smJ0NTFcW46QoWSe++TckwBGkcUgzkyDG
YgVlC+Jujr0xLRwa0zkAYDFVvMBheqV+Q8wUGSMCgYEAvaWSvYoXVZSU61IUrEQd
O5daHsKD8gpubECqFre9tnX0z/d2RqSzWgmDGnXsYRFr3ivH93NAxGqlrBhiMYag
SmYoNOwm6BHcc/fW40JL2/LyVequdwMxcyr4UiSlEaVoysNa0omB9u8EjzMLSG14
PPsEOWc1pgXiXxMNNscsFgUCgYEAtsfgHQ4eQrhcomnRgWuOfqB//khFcbd79SFv
bvzxCnvByzVgblqpxIiMfuMO4ygEQJSfQsFjBGuv7Cqgb2F7EFiQrp3ebXwt3LOp
k0KAFXdsuo+9u3nXO2eGIiHCCinpBJP1PhJiwul5dgFLY4U/ScJSt5iSqaZT5EF4
VAE4D20CgYAxs3bC/9p3wd15nw6W1OVTUtMTMc7nKNcxZw7ED7zhPMoaJYXC4GDM
zv5D6Z8KIBJbvNvRJZIRVhcT4Cr+prFr+YuCdIcyYE5TEElwNIddVhh5KZGYsGHF
o2NR47kFdYV4Lns4RR41o6ABs0UdxoOay6IG+fMPy3Gxf6wpSYnRQg==
-----END RSA PRIVATE KEY-----
```

- nginx.conf : echo-ip의 nginx설정 파일, 접속자의 ip주소를 응답하는 간단한 설정파일

```
#user  nobody;
worker_processes  1;
#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;
#pid        logs/nginx.pid;
events {
   worker_connections  1024;
}
http {
   include       mime.types;
   default_type  application/octet-stream;
      sendfile        on;
   server {
       listen       80;
       server_name  localhost;
       location / {
            default_type text/html;
           return 200 'request_method : $request_method | ip_dest: $server_addr\n';
       }
       error_page   500 502 503 504  /50x.html;
       location = /50x.html {
           root   html;
       }
   }
   server {
       listen 443 ssl;
       ssl_certificate /etc/nginx/conf.d/cert.crt;
       ssl_certificate_key /etc/nginx/conf.d/cert.key;

       ssl_protocols TLSv1.1 TLSv1.2;
       ssl_ciphers 'EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH';
       ssl_prefer_server_ciphers on;
       ssl_session_cache shared:SSL:10m;

       # disable any limits to avoid HTTP 413 for large image uploads
       client_max_body_size 0;

       location / {
            default_type text/html;
           return 200 'request_method : $request_method | ip_dest: $server_addr\n';
       }

   }
}
```

freestyle로 ci/cd 구성하는 순서

1. 깃허브에서 echo-ip를 빌드할 정보가 담긴 파일 받음(pull)
2. 받은 파일을 이용해 컨테이너 이미지 빌드
3. 빌드한 이미지를 레지스트리(192.168.1.10:8443)에 저장(push)
4. 레지스트리에 저장한 이미지를 쿠버네티스 클러스터에 디플로이먼트로 생성하고 로드밸런서 서비스로 노출

작업 중 화면을 길게 방치하면 403 오류 발생하는 이유

- 젠킨스에서 설정값을 입력하는 시간이 30분 이상 소유되거나 방치하면 저옵르 제출하고나 전환과정에서 403 no valid crumb 오류 발생,
- 젠킨스 보안 때문, 2.222.1 버전 부터 사이트 간 요청 위조 공격 방어를 위한 옵션이 강제로 활성화 되며 임의로 해제할 수 없다.
- 젠킨스는 서버로 통신할때 crumb라는 토큰정보를 입력하는데 화면이 오래 방치되면 이 토큰 정보가 만료되어오류가 발생
- 새로고침 후 재접속하면 됨

<br/>

Freestyle 프로젝트를 진행해보자.

1. Freestyle project 아이템을 생성하고 이름은 dpy-fs-dir-prod로 지정하자.
2. General 탭에서 Restric where this project can be run 체크를 해제한다.
    1. 이 설정은 젠킨스 에이전트가 특정한 레이블을 갖고 있을 때 해당 레이블을 가진 에이전트에서만 실행할 수 있도록 제한을 가하는 옵션인데 현재는 불필요하다.
3. 소스 코드 관리 탭에서는 젠킨스 외부에 있는 소크 코드 저장소를 젠킨스 CI로 사용하도록 지정한다.
    1. Git Repository URL을 입력하고 주요 브랜치 변경 내용에 대해서만 CI를 진행하도록 */master에서 */main으로 변경한다.
4. Build 단계를 추가한다. Add build step을 클릭해 Execute Shell을 선택한다. 이 항목에 입력한 셸 명령어로 빌드 작업이 수행된다.
5. 젠킨스에서 빌드에 사용할 명령어를 확인하고 입력한다. 명령어는 도커 이미지 빌드, 도커 이미지 푸시, 디플로이먼트 생성, 로드밸런서를 통한 노출의 4단계로 이뤄져있다. 이 스크립트는 사전에 구성돼 있으므로 cat 명령으로 스크립트를 출력한 후 복사한 다음 Execute Shell 메뉴를 누른 후 나온 칸에 입력하고 저장한다.
    
    ```bash
    cat ~/~~/echo-ip-101.freestyle
    docker build -t 192.168.1.10:8443/echo-ip .
    docker push 192.168.1.10:8443/echo-ip
    kubectl create deployment fs-echo-ip --image=192.168.1.10:8443/echo-ip
    kubectl expose deployment fs-echo-ip --type=LoadBalancer --name=fs-echo-ip-svc --port=8080 --target-port=80
    ```
    
6. 저장 버튼을 누르면 프로젝트 화면으로 돌아간다. Build Now를 눌러 저장한 프로젝트를 실행한다.
7. CI/CD 작업을 수행하면 Build History에 작업이 추가된다. 작업이 정상적으로 종료됐다면 파란색 표시를 볼 수 있다. 만약 작업이 실패하면 빨간색 표시가 나타난다.
8. 성공적으로 CI/CD 작업이 수행돼 파란색 원이 생성됐는는지 확인한다. 빨간색이라면 문제를 수정해야 한다.
9. 빌드 관련 자세한 내용을 보려면 Console Output 메뉴를 클릭한다. 콘솔 출력을 확인하면 작업의 진척 상황이나 실패 원인을 파악할 수 있다.
10. 슈퍼 푸티 창으로 돌아가 쿠버네티스 클러스터에 디플로이먼트와 로드밸런서가 정상적으로 배포됐는지 확인한다.
    
    ```bash
    kubectl get deployment
    kubectl get services
    ```



### Pipeline 프로젝트로 쉽게 echo-ip 배포하기

젠킨스의 Pipeline: 연속적인 작업을 코드 또는 파일로 정의해주는 젠킨스 기능.

1. 깃허브와 같은 소스 코드 저장소에서 빌드할 소스 코드와 젠킨스 내부 작업을 선언적인 문법으로 정의해 둔 Jenkinsfile을 내려 받음
2. 내려 받은 Jenkinsfile을 해석해 작성자의 의도에 맞는 작업을 자동으로 수행. 이 때 Jenkinsfile을 통해 이뤄지는 것은 앞서 한 Freestyle로 진행한 내용과 동일함


### 배포 과정 실습

1. 새로운 Item 버튼을 클릭해 Pipeline 프로젝트로 이름은 dpy-pi-bulk-prod로 정함
2. Gerneral 탭은 일반 설정 그대로 둠
3. Build Triggers 탭은 빌드를 유발하기 위한 조건을 설정하는 탭임
    1. 탭 옵션
        1. Build after other projects are built: 다른 프로젝트를 빌드한 이후 이 프로젝트를 빌드함. 특정 프로젝트를 빌드하기 위한 사전 조건을 구성해야 하는 경우 또는 여러 개의 프로젝트를 빌드할 때 순서에 따른 의존 관계가 있는 경우 유용함
        2. Build periodically: 주기적으로 프로젝트 빌드를 수행한다. 일정 주기로 빌드를 수행하는 경우 사용할 수 있다. 예를 들어, 매일 최신 버전의 소프트웨어를 배포하는 방식으로 야간 빌드(Nightly build)라고 하는데 이런 작업을 위해 1일 주기로 작업을 설정할 수 있다. 주기를 설정할 때는 크론(Cron)이라는 스케줄 도구의 문법을 활용해 작성한다.
        3. Poll SCM: 깃허브 등 소스 코드 저장소에서 주기적으로 내용을 검사해 빌드한다. Poll SCM 또한 크론 문법을 사용해 주기적으로 빌드를 수행한다. Build periodically와 차이점은 Poll SCM은 빌드를 수행하기 전 소스 코드 저장소의 내용에 변경이 있는지 확인한다. 이후 변경이 있을 때만 빌드를 수행한다.
        4. 빌드 안함: 빌드를 사용하지 않음. 임시로 사용하지 않을 프로젝트 등에 설정할 수 있다. 
        5. Quiet period: 빌드를 실행할 때 약간의 지연 시간을 주는 옵션이다. 지연 시간의 범위 이내에서 들어온 요청은 한 건으로 처리하기 때문에 불필요한 작업의 중복을 방지할 수 있습니다. 예를 들어 Quied period를 5초로 설정한다면, 여러 번의 푸시가 들어오더라도 5초 내에 들어온 마지막 푸시만을 실행한다. 단 젠킨스의 UI의 Build Now는 즉시 작업을 수행하기 때문에 이 값을 생략한다. 깃허브 같은 소스 코드 저장소와 연계해 외부의 요청으로부터 작업을 수행하는 경우 적용할 수 있다.
        6. 빌드를 원격으로 유발: 외부의 연계를 위해 젠킨스의 빌드 작업을 외부에서 URL을 호출해 시작할 때 사용한다. 이 옵션을 선택하면 작업 실행 권한의 인증을 위한 토큰을 입력할 수 있다. 토큰을 설정한 경우 <JENKINS_URL>/job/<작업명>/build?token=<토큰 이름>의 형식으로 URL을 호출하면 빌드 작업이 시작된다. 이 주소는 주로 깃허브의 푸시 또는 메신저의 웹훅(webhook)과 같이 주소를 이용해 빌드를 시작할 수 있는 곳에서 사용된다.
4. Advanced Project Options 탭은 프로젝트의 고급 옵션을 설정하는 곳으로 젠킨스의 플러그인 설치에 따라 생성된다. 이번 실습에서 건너 뜀.
5. Pipeline 탭에서는 젠킨스의 빌드 작업 절차를 정의할 수 있다. 빌드 작업을 위한 스크립트를 직접 입력하거나 외부의 소스 코드 저장소에서 선언적인 문법으로 작성한 파일을 갖고 와서 빌드 작업을 수행할 수 있다. Definition에서 Pipeline script를 선택할 경우 해당 화면에서 Freestyle과 같이 직접 입력한 내용을 사용한다. 여기서는 이미 작성된 파일로 ci/cd를 구현함으로 Definition을 Pipeline script from SCM으로 선택한다.
6. 외부 저장소에서 선언적인 문법으로 작성된 파일을 갖고 오기 위해 레포지터리와 브랜치를 지정한다.
7. 저장함
8. Build Now를 클릭해 젠킨스의 빌드 및 배포 작업을 시작
9. 각 스테이지별로 배포가 정상 완료된 것을 확인했으면 실제 쿠버네티스 클러스터에 디플로이먼트와 로드밸런서가 정상적으로 배포됐는지 확인
    
    ```bash
    kubectl get deployments
    kubectl get services
    ```
    

**Jenkinsfile의 구조**

- pipeline: 선언적인 문법이 시작하는 부분. 선언적인 문법으로 작성된 작업들은 pipeline {}의 사이에 작업 내용을 작성해야 한다.
- agent: 작업을 수행할 에이전트를 지정하고 필요한 설정을 한다. 지정된 에이전트 내부에선 젠킨스 빌드 작업이 실제로 수행되는데 다음과 같이 여러 가지 방식으로 지정할 수 있다. 첫 번째는 사용 가능한 에이전트를 젠킨스가 임의로 지정하는 any, 두 번째는 특정 레이블과 일치하는 에이전트 노드를 지정하는 label, 세 번째는 에이전트 노드의 이미지를 도커로 지정하는 docker, 네 번째는 에이전트 노드를 쿠버네티스 파드로 지정하는 kubernetes와 같은 것들이 있다. 플러그인에 따라 지정할 에이전트는 무수히 많다. agent any로 사용하면 현재 설정된 에이전트가 하나만 존재하기 때문에 설정된 에이전트를 통해 빌드 작업을 수행하게 된다.
- stages: stage들을 모아 정의하고 이를 순서대로 진행하게 해 준다.
- stage: step들을 정의하는 영역. stage는 괄호 안에 여러 개의 step들을 정의할 수 있는데 이 step들 내부에서 실제로 동작하는 내용들이 정의된다. 그리고 젠킨스에서 빌드가 진행될 때 stage별로 진행 단계를 확인할 수 있다.
- steps: stage 내부에서 실제 작업을 내용을 작성하는 영역. stage 내부에 여러 step이 존재할 수 있다. step 영역 내부에서 script, sh, git 같은 작업을 통해 실제 작동하게 된다.

**Jenkinsfile**

```bash
pipeline {
  agent any
  stages {
// 소스 코드 저장소로부터 깃헙 소스 코드를 내려 받음
    stage('git scm update') {
      steps {
        git url: 'https://github.com/IaC-Source/echo-ip.git', branch: 'main'
      }
    }

// 도커 명령을 이용해 컨테이너 이미지를 빌드하고, 빌드한 이미지를 레지스트리에 저장하는 작업을 수행
    stage('docker build and push') {
      steps {
        sh '''
        docker build -t 192.168.1.10:8443/echo-ip .
        docker push 192.168.1.10:8443/echo-ip
        '''
      }
    }

// kubectl 명령으로 전 단계에서 레지스트리에 저장한 이미지를 pl-bulk-prod로 배포하고,
// 배포한 pl-bulk-prod를 kubectl 명령으로 로드 밸런서 타입으로 노출하는 작업 수행
    stage('deploy kubernetes') {
      steps {
        sh '''
        kubectl create deployment pl-bulk-prod --image=192.168.1.10:8443/echo-ip
        kubectl expose deployment pl-bulk-prod --type=LoadBalancer --port=8080 \
                                               --target-port=80 --name=pl-bulk-prod-svc
        '''
      }
    }
  }
}
```

### Pipeline 프로젝트로 구현하는 블루그린 배포 전략

Rolling-Update: pod을 레플리카셋 단위로 나눠 모든 레플리카셋에 속해 있는 pod이 업데이트된 후 레플리카셋을 삭제함. 내부 pod 개수가 많으면 업데이트 과정이 길어져 다른 두 가지 버전이 오랫동안 공존하는 경우가 있다. 이를 방지하기 위해 블루그린 배포 전략을 사용함

블루 그린 전략 : ‘모든 pod’이 업데이트된 이후에 트래픽을 전달하자, 즉 서비스의 중단 없이 연속적으로 배포가 가능하다. 문제가 발생한 경우 기존 서비스하던 디플로이먼트(블루)로 원복하는 것도 수월해 장애 복구가 쉽다. 단, 기존 배포 대비 최소 2배 이상의 리소스가 필요하다는 제약이 있다.

블루그린 배포 전략을 이용해 배포하기

1. 새로운 Item 생성
2. Pipeline을 선택하고 이름을 dpy-pl-blue-green으로 선택
3. Definition에 Pipeline script from SCM을 선택
    1. SCM을 Git으로 하고 Repository URL을 입력하고 브랜치 main으로 선택(*/main)
    2. Script Path에 Jenkinsfile 입력(jenkinsfile은 기존과 달리 agent 부분이 any가 아닌 kubernetes로 변경해 블루그린 배포를 위한 에이전트를 별도로 설정하고, 이를 yaml 파일로 작성해 적용함) → 블루그린 배포에 동적으로 변동되는 오브젝트 값을 설정하려면 kustomize와 같은 도구를 사용해야 하기 때문
    

Jenkinsfile

```bash
pipeline {
  agent {
    kubernetes {
      yaml '''
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          app: blue-green-deploy
        name: blue-green-deploy
      spec:
        containers:
        - name: kustomize
          image: sysnet4admin/kustomize:3.6.1
          tty: true
          volumeMounts:
          - mountPath: /bin/kubectl
            name: kubectl
          command:
          - cat
        serviceAccount: jenkins
        volumes:
        - name: kubectl
          hostPath:
            path: /bin/kubectl
      '''
    }
  }
  stages {
    stage('git scm update'){
      steps {
        git url: 'https://github.com/IaC-Source/blue-green.git', branch: 'main'
      }
    }
    stage('define tag'){
      steps {
        script {
          if(env.BUILD_NUMBER.toInteger() % 2 == 1){
            env.tag = "blue"
          } else {
            env.tag = "green"
          }
        }
      }
    }
    stage('deploy configmap and deployment'){
      steps {
        container('kustomize'){
          dir('deployment'){
            sh '''
            kubectl apply -f configmap.yaml
            kustomize create --resources ./deployment.yaml
            echo "deploy new deployment"
            kustomize edit add label deploy:$tag -f
            kustomize edit set namesuffix -- -$tag
            kustomize edit set image sysnet4admin/dashboard:$tag
            kustomize build . | kubectl apply -f -
            echo "retrieve new deployment"
            kubectl get deployments -o wide
            '''
          }
        }
      }    
    }
    stage('switching LB'){
      steps {
        container('kustomize'){
          dir('service'){
            sh '''
            kustomize create --resources ./lb.yaml
            while true;
            do
              export replicas=$(kubectl get deployments \
              --selector=app=dashboard,deploy=$tag \
              -o jsonpath --template="{.items[0].status.replicas}")
              export ready=$(kubectl get deployments \
              --selector=app=dashboard,deploy=$tag \
              -o jsonpath --template="{.items[0].status.readyReplicas}")
              echo "total replicas: $replicas, ready replicas: $ready"
              if [ "$ready" -eq "$replicas" ]; then
                echo "tag change and build deployment file by kustomize" 
                kustomize edit add label deploy:$tag -f
                kustomize build . | kubectl apply -f -
                echo "delete $tag deployment"
                kubectl delete deployment --selector=app=dashboard,deploy!=$tag
                kubectl get deployments -o wide
                break
              else
                sleep 1
              fi
            done
            '''
          }
        }
      }
    }
  }
}
```